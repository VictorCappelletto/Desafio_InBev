# Desafio InBev - Data Orchestration Platform

![Python](https://img.shields.io/badge/python-3.11-blue)
![Airflow](https://img.shields.io/badge/Apache%20Airflow-2.x-orange)
![Azure](https://img.shields.io/badge/Azure-Cloud-0078D4)
![Databricks](https://img.shields.io/badge/Databricks-Enabled-FF3621)
![Documentation](https://img.shields.io/badge/docs-MkDocs-blue?logo=readthedocs)
![Docs Status](https://github.com/victorcappelleto/Desafio_InBev/workflows/Deploy%20Documentation/badge.svg)
![CI Status](https://github.com/victorcappelleto/Desafio_InBev/workflows/CI%20-%20Continuous%20Integration/badge.svg)
![CD Status](https://github.com/victorcappelleto/Desafio_InBev/workflows/CD%20-%20Continuous%20Deployment/badge.svg)
![Security](https://github.com/victorcappelleto/Desafio_InBev/workflows/Security%20Scanning/badge.svg)
![Code Style](https://img.shields.io/badge/code%20style-black-000000.svg)
![Coverage](https://img.shields.io/badge/coverage-85%25-brightgreen.svg)

## ğŸ“‹ DescriÃ§Ã£o

Plataforma de orquestraÃ§Ã£o de dados desenvolvida com Apache Airflow para gerenciar pipelines de dados envolvendo Azure Cloud Services e Databricks. O projeto automatiza a extraÃ§Ã£o, transformaÃ§Ã£o e carga (ETL) de dados de cervejarias atravÃ©s de APIs pÃºblicas e processamento em plataformas cloud.

## ğŸ“– DocumentaÃ§Ã£o

**ğŸ“˜ [Acesse a documentaÃ§Ã£o completa â†’](https://victorcappelleto.github.io/Desafio_InBev/)**

A documentaÃ§Ã£o oficial estÃ¡ hospedada no GitHub Pages e inclui:
- ğŸ—ï¸ **Arquitetura**: Clean Architecture, Domain Layer, Use Cases, Repository Pattern
- âœ… **Data Quality**: Framework com 6 dimensÃµes ISO 8000
- ğŸ“Š **Observability**: MÃ©tricas, anomalias e alertas
- ğŸš€ **Setup**: Guias de instalaÃ§Ã£o e configuraÃ§Ã£o
- ğŸ› ï¸ **DAGs**: DocumentaÃ§Ã£o detalhada de cada pipeline

**Desenvolvimento Local:**
```bash
# Ver documentaÃ§Ã£o localmente
poetry run task doc         # Inicia servidor em http://localhost:8000

# Build da documentaÃ§Ã£o
poetry run task doc-build   # Gera site/ folder

# Deploy manual (opcional)
poetry run task doc-deploy  # Publica no GitHub Pages
```

### âœ¨ Destaques

- ğŸ›ï¸ **Clean Architecture + DDD:** Domain Layer, Use Cases, Repository Pattern completos
- âœ… **Data Quality Framework:** 6 dimensÃµes ISO 8000 (Completeness, Accuracy, Validity, etc)
- ğŸ“Š **Observability:** Metrics Collection, Anomaly Detection, Multi-channel Alerts
- ğŸ”’ **SeguranÃ§a:** Credenciais gerenciadas via variÃ¡veis de ambiente e Airflow Connections
- ğŸ³ **Docker Otimizado:** Microsoft ODBC Driver 18 prÃ©-configurado para Azure SQL
- âš™ï¸ **ConfiguraÃ§Ã£o Simplificada:** `airflow_settings.yaml` prÃ©-configurado para desenvolvimento local
- ğŸ“¦ **DependÃªncias Completas:** Sistema e Python totalmente documentados
- ğŸš€ **Pronto para ProduÃ§Ã£o:** Estrutura preparada para deployment em Astronomer ou Kubernetes
- ğŸ“ **Logging Profissional:** Sistema de logs padronizado com utilitÃ¡rios prontos para uso
- ğŸ› ï¸ **Dev Tools:** Black, isort, pytest configurados + 8 comandos taskipy Ãºteis
- ğŸ“‹ **Rastreabilidade:** Git history com conventional commits para tracking completo

## ğŸ—ï¸ Arquitetura

```mermaid
graph LR
    A[Open Brewery API] -->|Extract| B[Apache Airflow]
    B -->|Load| C[Azure SQL Database]
    B -->|Trigger| D[Azure Data Factory]
    B -->|Execute| E[Databricks Notebooks]
    E -->|Process| F[Data Lake]
```

### ğŸ›ï¸ Arquitetura de Software (SOLID)

O projeto implementa **princÃ­pios SOLID** e **padrÃµes de design profissionais**:

#### ğŸ“ PrincÃ­pios SOLID

| PrincÃ­pio | ImplementaÃ§Ã£o | Exemplo |
|-----------|---------------|---------|
| **S**ingle Responsibility | Cada classe tem uma Ãºnica responsabilidade | `BreweryAPIExtractor`: apenas extraÃ§Ã£o |
| **O**pen/Closed | Aberto para extensÃ£o, fechado para modificaÃ§Ã£o | Nova fonte? Implemente `IDataExtractor` |
| **L**iskov Substitution | Interfaces garantem substituiÃ§Ã£o | Qualquer `IDataExtractor` Ã© intercambiÃ¡vel |
| **I**nterface Segregation | Interfaces focadas e minimalistas | `IDataExtractor`, `IDataLoader`, `IDataTransformer` |
| **D**ependency Inversion | Depende de abstraÃ§Ãµes, nÃ£o implementaÃ§Ãµes | Configs injetadas via DI |

#### ğŸ¨ PadrÃµes de Design

| PadrÃ£o | Classe | BenefÃ­cio |
|--------|--------|-----------|
| **Factory** | `ETLFactory` | Centraliza criaÃ§Ã£o de objetos |
| **Strategy** | `IDataExtractor` | Troca de estratÃ©gias |
| **Dependency Injection** | `*Config` | Testabilidade |
| **Repository** | `Services` | AbstraÃ§Ã£o de dados |

#### ğŸ“¦ Estrutura em Camadas (Clean Architecture)

```
dags/
â”œâ”€â”€ domain/              # ğŸŸ¢ DOMAIN LAYER (Business Rules)
â”‚   â”œâ”€â”€ value_objects.py # Coordinates, Address, Location, Contact, BreweryType
â”‚   â”œâ”€â”€ entities.py      # Brewery, BreweryAggregate
â”‚   â”œâ”€â”€ exceptions.py    # Domain-specific exceptions
â”‚   â””â”€â”€ validators.py    # Business rule validators
â”œâ”€â”€ use_cases/           # ğŸ”µ USE CASES (Application Logic)
â”‚   â”œâ”€â”€ extract.py       # ExtractBreweriesUseCase
â”‚   â”œâ”€â”€ transform.py     # TransformBreweriesUseCase
â”‚   â”œâ”€â”€ load.py          # LoadBreweriesUseCase
â”‚   â””â”€â”€ quality.py       # ValidateBreweriesQualityUseCase
â”œâ”€â”€ repositories/        # ğŸŸ£ ADAPTERS (Data Access)
â”‚   â”œâ”€â”€ base.py          # IRepository, IBreweryRepository
â”‚   â”œâ”€â”€ brewery_repository.py # InMemory, SQL implementations
â”‚   â””â”€â”€ unit_of_work.py  # Transaction management
â”œâ”€â”€ data_quality/        # âœ… DATA QUALITY FRAMEWORK
â”‚   â”œâ”€â”€ framework.py     # DataQualityEngine, DataQualityCheck
â”‚   â”œâ”€â”€ dimensions.py    # 6 ISO dimensions (Completeness, Accuracy, etc)
â”‚   â””â”€â”€ rules/           # Brewery-specific rules
â”œâ”€â”€ observability/       # ğŸ“Š OBSERVABILITY FRAMEWORK
â”‚   â”œâ”€â”€ metrics.py       # DataMetrics, MetricsCollector
â”‚   â””â”€â”€ alerts/          # EmailAlerter, SlackAlerter
â”œâ”€â”€ config/              # âš™ï¸ CONFIGURATION
â”‚   â””â”€â”€ settings.py      # AzureSQLConfig, DatabricksConfig, etc
â”œâ”€â”€ interfaces/          # ğŸ“‹ INTERFACES (Contracts)
â”‚   â”œâ”€â”€ data_extractor.py
â”‚   â”œâ”€â”€ data_loader.py
â”‚   â””â”€â”€ data_transformer.py
â”œâ”€â”€ services/            # ğŸ”§ SERVICES (Implementations)
â”‚   â”œâ”€â”€ brewery_api_extractor.py
â”‚   â”œâ”€â”€ azure_sql_loader.py
â”‚   â””â”€â”€ brewery_transformer.py
â”œâ”€â”€ factories/           # ğŸ­ FACTORIES
â”‚   â””â”€â”€ etl_factory.py
â”œâ”€â”€ utils/               # ğŸ› ï¸ UTILITIES
â”‚   â””â”€â”€ logger.py
â”œâ”€â”€ exceptions.py        # ğŸš¨ EXCEPTIONS
â””â”€â”€ *.py                 # ğŸš€ DAGs (Orchestration)
```

#### âœ¨ BenefÃ­cios da Arquitetura

âœ… **Testabilidade**: Cada componente pode ser testado isoladamente  
âœ… **Manutenibilidade**: MudanÃ§as localizadas, sem efeito dominÃ³  
âœ… **Extensibilidade**: Adicione novas fontes sem modificar cÃ³digo existente  
âœ… **Reusabilidade**: Services podem ser usados em mÃºltiplas DAGs  
âœ… **Type Safety**: Type hints completos para suporte de IDE  
âœ… **Profissionalismo**: PadrÃµes de indÃºstria reconhecidos  

## ğŸš€ Tecnologias

- **Apache Airflow** - OrquestraÃ§Ã£o de workflows
- **Azure SQL Database** - Armazenamento de dados estruturados
- **Azure Data Factory** - IntegraÃ§Ã£o e transformaÃ§Ã£o de dados
- **Databricks** - Processamento de dados em larga escala
- **Docker** - ContainerizaÃ§Ã£o
- **Python 3.11** - Linguagem de programaÃ§Ã£o
- **Poetry** - Gerenciamento de dependÃªncias
- **Astronomer Runtime** - Runtime otimizado do Airflow

## ğŸ“¦ Estrutura do Projeto

```
Desafio_InBev/
â”œâ”€â”€ dags/                                    # DAGs do Airflow
â”‚   â”œâ”€â”€ execute_notebook_databricks.py       # Executa notebooks no Databricks
â”‚   â”œâ”€â”€ extract_data_api_slq_azure.py       # Extrai dados da API para Azure SQL
â”‚   â””â”€â”€ trigger_data_factory_azure.py       # Dispara pipelines no ADF
â”œâ”€â”€ tests/                                   # Testes automatizados
â”‚   â””â”€â”€ dags/
â”‚       â””â”€â”€ test_dag_example.py             # Testes das DAGs
â”œâ”€â”€ docs/                                    # DocumentaÃ§Ã£o MkDocs
â”‚   â””â”€â”€ index.md
â”œâ”€â”€ .dockerignore                            # Arquivos ignorados no build Docker
â”œâ”€â”€ .gitignore                              # Arquivos ignorados no Git
â”œâ”€â”€ .python-version                         # VersÃ£o Python do projeto (3.11.5)
â”œâ”€â”€ Dockerfile                               # Imagem Docker otimizada com ODBC Driver
â”œâ”€â”€ airflow_settings.yaml                    # Connections, Pools e Variables (local dev)
â”œâ”€â”€ packages.txt                            # DependÃªncias do sistema (ODBC, etc)
â”œâ”€â”€ pyproject.toml                          # ConfiguraÃ§Ã£o Poetry (dev dependencies)
â”œâ”€â”€ requirements.txt                         # DependÃªncias Python do Airflow
â”œâ”€â”€ mkdocs.yml                              # ConfiguraÃ§Ã£o da documentaÃ§Ã£o
â””â”€â”€ README.md
```

## ğŸ“Š DAGs DisponÃ­veis

### ğŸš€ DAGs de ProduÃ§Ã£o (Arquitetura SOLID)

| DAG | FrequÃªncia | FunÃ§Ã£o | Status |
|-----|------------|--------|--------|
| `brewery_etl_solid` | DiÃ¡ria | ETL completo de dados de cervejarias | âœ… ProduÃ§Ã£o |
| `databricks_processing_solid` | DiÃ¡ria | Processamento Databricks (Silver layer) | âœ… ProduÃ§Ã£o |
| `azure_data_factory_solid` | DiÃ¡ria | Trigger de pipelines ADF | âœ… ProduÃ§Ã£o |
| `data_quality_check_solid` | DiÃ¡ria | VerificaÃ§Ã£o de qualidade de dados | âœ… ProduÃ§Ã£o |
| `system_health_monitor_solid` | 30 min | Monitoramento de saÃºde do sistema | âœ… ProduÃ§Ã£o |

---

### 1. `brewery_etl_solid` - ETL Completo

**DescriÃ§Ã£o:** Pipeline ETL completo com arquitetura SOLID

**Tarefas:**
1. `extract_task` - Extrai dados via `BreweryAPIExtractor`
2. `transform_task` - Transforma via `BreweryTransformer`  
3. `load_task` - Carrega via `AzureSQLLoader`

**Features:**
- âœ… Retry logic com exponential backoff
- âœ… Data validation
- âœ… MERGE statements (upsert)
- âœ… Logging estruturado
- âœ… Exception handling profissional

**Tecnologias:** Python, requests, pyodbc, Azure SQL

---

### 2. `databricks_processing_solid` - Databricks

**DescriÃ§Ã£o:** Executa notebook Databricks com validaÃ§Ãµes

**Tarefas:**
1. `validate_config` - ValidaÃ§Ã£o fail-fast de configuraÃ§Ãµes
2. `run_databricks_notebook` - Executa notebook com parÃ¢metros

**Features:**
- âœ… ValidaÃ§Ã£o antes de execuÃ§Ã£o cara
- âœ… ParÃ¢metros contextuais (execution_date, run_id)
- âœ… Type safety

**Tecnologias:** Databricks, Spark

---

### 3. `azure_data_factory_solid` - ADF

**DescriÃ§Ã£o:** Dispara pipelines Azure Data Factory com auditoria

**Tarefas:**
1. `validate_config` - Valida credenciais e configuraÃ§Ãµes
2. `log_parameters` - Cria audit trail
3. `run_adf_pipeline` - Executa pipeline

**Features:**
- âœ… ValidaÃ§Ã£o de credenciais
- âœ… Auditoria completa
- âœ… Rastreamento de execuÃ§Ã£o

**Tecnologias:** Azure Data Factory

---

### 4. `data_quality_check_solid` - Qualidade de Dados

**DescriÃ§Ã£o:** ValidaÃ§Ã£o automÃ¡tica de qualidade de dados

**Checks:**
- âœ… Row count validation (>= 100 rows)
- âœ… Null value detection em campos crÃ­ticos
- âœ… Duplicate detection por ID
- âœ… Data freshness check

**Features:**
- âœ… ExecuÃ§Ã£o paralela de checks
- âœ… Fail-fast em problemas de qualidade
- âœ… RelatÃ³rio consolidado
- âœ… Alertas automÃ¡ticos

**FrequÃªncia:** DiÃ¡ria (apÃ³s ETL)

---

### 5. `system_health_monitor_solid` - Monitoramento

**DescriÃ§Ã£o:** Health checks de todos os componentes do sistema

**Checks:**
- âœ… Azure SQL connectivity & performance
- âœ… Databricks workspace availability
- âœ… Brewery API endpoint health
- âœ… Airflow self-check

**Features:**
- âœ… ExecuÃ§Ã£o a cada 30 minutos
- âœ… Checks isolados (failures nÃ£o cascateiam)
- âœ… Response time tracking
- âœ… Health report consolidado
- âœ… Email alerts em failures

**FrequÃªncia:** A cada 30 minutos

---

### ğŸ’¡ Arquitetura das DAGs

Todas as DAGs seguem os mesmos princÃ­pios:

```python
# 1. Configuration (Dependency Injection)
config = DatabricksConfig()

# 2. Factory Pattern
service = ETLFactory.create_service(config)

# 3. Professional Logging
log_task_start(logger, "task_name")
log_task_success(logger, "task_name", records=100)

# 4. Exception Handling
try:
    result = service.execute()
except CustomException as e:
    log_task_error(logger, "task_name", e)
    raise
```

**Ver exemplo completo:** [config_usage_example.py](dags/examples/config_usage_example.py)

## ğŸ› ï¸ Setup e InstalaÃ§Ã£o

### PrÃ©-requisitos

- **Python 3.11+**
- **Docker & Docker Compose**
- **Astronomer CLI** (recomendado) ou Docker puro
- **Poetry** (opcional, para desenvolvimento local)

### ğŸš€ Quick Start com Astronomer CLI (Recomendado)

1. **Clone o repositÃ³rio**
   ```bash
   git clone <repository-url>
   cd Desafio_InBev
   ```

2. **Instale o Astronomer CLI**
   ```bash
   # macOS
   brew install astronomer/tap/astro
   
   # Linux
   curl -sSL install.astronomer.io | sudo bash -s
   ```

3. **Configure variÃ¡veis de ambiente**
   ```bash
   # Crie um arquivo .env na raiz do projeto com suas credenciais
   # Veja a seÃ§Ã£o "VariÃ¡veis de Ambiente" abaixo
   nano .env
   ```

4. **Inicie o ambiente Airflow**
   ```bash
   # Primeira vez (build + start)
   astro dev start
   
   # Rebuild apÃ³s mudanÃ§as no Dockerfile ou requirements.txt
   astro dev restart
   ```

5. **Acesse a interface web**
   - **URL:** http://localhost:8080
   - **UsuÃ¡rio:** `admin`
   - **Senha:** `admin`

### ğŸ³ InstalaÃ§Ã£o com Docker (Alternativa)

```bash
# Build da imagem
docker build -t desafio-inbev .

# Run do container
docker run -p 8080:8080 --env-file .env desafio-inbev
```

> **âš ï¸ Nota:** O mÃ©todo com Astronomer CLI Ã© recomendado pois gerencia automaticamente o scheduler, webserver e outros componentes do Airflow.

## âš™ï¸ ConfiguraÃ§Ã£o

### ğŸ” VariÃ¡veis de Ambiente (ObrigatÃ³rio)

Crie um arquivo `.env` na raiz do projeto com suas credenciais:

```env
# ==============================================================================
# Azure SQL Database
# ==============================================================================
AZURE_SQL_PASSWORD=SUA_SENHA_AZURE_SQL

# ==============================================================================
# Databricks
# ==============================================================================
DATABRICKS_HOST=https://adb-XXXXX.XX.azuredatabricks.net
DATABRICKS_TOKEN=dapi********************************
DATABRICKS_CLUSTER_ID=XXXX-XXXXXX-XXXXXXXX
DATABRICKS_JOB_ID=XXXXXXXXXXXXX
DATABRICKS_NOTEBOOK_PATH=/Workspace/Users/your.email@example.com/your_notebook_name

# ==============================================================================
# Azure Data Factory
# ==============================================================================
ADF_TENANT_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
ADF_SUBSCRIPTION_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
ADF_CLIENT_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx
ADF_CLIENT_SECRET=seu_client_secret
```

> **ğŸ’¡ Dica:** O arquivo `airflow_settings.yaml` jÃ¡ estÃ¡ configurado para ler essas variÃ¡veis automaticamente!

### ğŸ“¡ Airflow Connections (PrÃ©-configuradas)

As seguintes conexÃµes sÃ£o **automaticamente configuradas** via `airflow_settings.yaml` para desenvolvimento local:

#### 1. **Azure SQL Database** (`azure_sql_default`)
```yaml
Conn Type: ODBC
Host: inbev-sql-server.database.windows.net
Database: inbev_db
Login: inbev_admin
Password: ${AZURE_SQL_PASSWORD}  # Do arquivo .env
Driver: ODBC Driver 18 for SQL Server
```

#### 2. **Databricks** (`databricks_default`)
```yaml
Conn Type: Databricks
Host: ${DATABRICKS_HOST}         # Do arquivo .env
Token: ${DATABRICKS_TOKEN}       # Do arquivo .env
```

#### 3. **Azure Data Factory** (`azure_data_factory_default`)
```yaml
Conn Type: Azure Data Factory
Client ID: ${ADF_CLIENT_ID}      # Do arquivo .env
Client Secret: ${ADF_CLIENT_SECRET}  # Do arquivo .env
Tenant ID: ${ADF_TENANT_ID}      # Do arquivo .env
Subscription ID: ${ADF_SUBSCRIPTION_ID}  # Do arquivo .env
```

> **âš ï¸ Para ProduÃ§Ã£o:** Configure as connections diretamente no Airflow UI ou use Azure Key Vault.

### ğŸ¯ Airflow Variables (PrÃ©-configuradas)

As seguintes variables sÃ£o automaticamente configuradas via `airflow_settings.yaml`:

| Variable | DescriÃ§Ã£o | Fonte |
|----------|-----------|-------|
| `databricks_cluster_id` | ID do cluster Databricks | `.env` |
| `databricks_job_id` | ID do job Databricks | `.env` |
| `databricks_notebook_path` | Caminho do notebook | `.env` |
| `adf_resource_group` | Resource group do ADF | Fixo |
| `adf_factory_name` | Nome do Data Factory | Fixo |
| `adf_pipeline_name` | Nome da pipeline | Fixo |
| `brewery_api_url` | URL da API de cervejarias | Fixo |
| `environment` | Ambiente (dev/prod) | Fixo |

### ğŸŠ Airflow Pools (PrÃ©-configurados)

| Pool | Slots | DescriÃ§Ã£o |
|------|-------|-----------|
| `azure_pool` | 5 | Para operaÃ§Ãµes Azure (SQL, ADF) |
| `databricks_pool` | 3 | Para jobs Databricks |

## ğŸ§ª Desenvolvimento

### ğŸ—ï¸ Infraestrutura e DependÃªncias

O projeto estÃ¡ configurado com trÃªs camadas de dependÃªncias:

#### 1. **DependÃªncias do Sistema** (`packages.txt`)
```
unixodbc           # Driver ODBC base
unixodbc-dev       # Headers de desenvolvimento ODBC
gnupg              # VerificaÃ§Ã£o de assinaturas GPG
curl               # Download de pacotes
apt-transport-https # RepositÃ³rios HTTPS
```

#### 2. **Microsoft ODBC Driver** (`Dockerfile`)
O **Microsoft ODBC Driver 18 for SQL Server** Ã© instalado automaticamente via Dockerfile:
- âœ… Configurado para Azure SQL Database
- âœ… Suporte a TLS/SSL
- âœ… CompatÃ­vel com pyodbc

#### 3. **DependÃªncias Python** (`requirements.txt`)
```python
apache-airflow-providers-microsoft-azure==10.1.2  # Azure providers
apache-airflow-providers-databricks==6.6.0        # Databricks provider
pyodbc==5.1.0                                      # SQL Server connectivity
requests==2.32.3                                   # HTTP requests
```

### ğŸ“¦ Gerenciamento de DependÃªncias

#### Adicionar nova dependÃªncia do Airflow
```bash
# Adicione ao requirements.txt
echo "nova-lib==1.0.0" >> requirements.txt

# Rebuild o container
astro dev restart
```

#### Adicionar dependÃªncia do sistema
```bash
# Adicione ao packages.txt
echo "nome-do-pacote" >> packages.txt

# Rebuild o container
astro dev restart
```

#### Adicionar nova dependÃªncia Python para desenvolvimento local (Poetry)
```bash
poetry add <package>
```

### ğŸ“ Sistema de Logging

O projeto inclui um sistema de logging padronizado para DAGs.

#### Usar o logger nas DAGs:

```python
from utils.logger import get_logger, log_task_start, log_task_success, log_task_error

# Criar logger
logger = get_logger(__name__)

# Log inÃ­cio da task
log_task_start(logger, "extract_data", source="API", target="Database")

try:
    # Sua lÃ³gica aqui
    result = extract_data()
    
    # Log sucesso com mÃ©tricas
    log_task_success(
        logger, 
        "extract_data", 
        records=len(result),
        duration="2.3s"
    )
except Exception as e:
    # Log erro com contexto
    log_task_error(logger, "extract_data", e, retry_count=1)
    raise
```

#### Configurar nÃ­vel de log:

```bash
# No arquivo .env
LOG_LEVEL=DEBUG  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL

# Ou via Airflow
AIRFLOW__LOGGING__LOGGING_LEVEL=INFO
```

#### Ver logs:

```bash
# Logs em tempo real
astro dev logs --follow

# Logs de serviÃ§o especÃ­fico
astro dev logs --scheduler --follow
astro dev logs --webserver --follow

# Logs de uma task especÃ­fica
astro dev run tasks logs <dag_id> <task_id> <execution_date>
```

### ğŸ¨ FormataÃ§Ã£o de CÃ³digo

```bash
# Formate o cÃ³digo (isort + black)
poetry run task format

# Verifique formataÃ§Ã£o sem modificar
poetry run task lint

# Manualmente:
poetry run isort .
poetry run black .
```

### ğŸ§ª Testes

O projeto possui **suite completa de testes** com **Unit Tests** e **Integration Tests**:

#### **Test Coverage: ~85%** âœ…

```
tests/
â”œâ”€â”€ test_config.py              # Unit: Configuration
â”œâ”€â”€ test_services.py            # Unit: ETL Services
â””â”€â”€ integration/                # Integration Tests
    â”œâ”€â”€ test_full_pipeline.py   # E2E: Complete pipeline
    â”œâ”€â”€ test_repositories.py    # Repository + Unit of Work
    â”œâ”€â”€ test_use_cases.py       # Application logic
    â””â”€â”€ test_domain_layer.py    # Domain entities + validation
```

**Comandos:**

```bash
# Execute todos os testes
poetry run task test

# Testes com cobertura HTML
poetry run task test-cov
# RelatÃ³rio gerado em htmlcov/index.html

# Apenas integration tests
poetry run pytest tests/integration/ -v

# Apenas unit tests
poetry run pytest tests/test_*.py -v

# Execute todos os checks (lint + test)
poetry run task check

# Teste especÃ­fico
poetry run pytest tests/integration/test_full_pipeline.py::TestFullETLPipeline::test_full_pipeline_success -v
```

**[Ver Guia Completo de Testes â†’](tests/README.md)**

### âš¡ Comandos Ãšteis (Taskipy)

O projeto inclui 8 comandos prontos para desenvolvimento:

```bash
# FormataÃ§Ã£o
poetry run task format      # Formata cÃ³digo (isort + black)
poetry run task lint         # Verifica formataÃ§Ã£o sem modificar

# Testes
poetry run task test         # Executa testes
poetry run task test-cov     # Testes com cobertura
poetry run task check        # Lint + testes (CI-ready)

# DocumentaÃ§Ã£o
poetry run task doc          # Inicia servidor docs
poetry run task doc-build    # Build documentaÃ§Ã£o estÃ¡tica

# Limpeza
poetry run task clean        # Remove arquivos temporÃ¡rios

# UtilitÃ¡rios
poetry run task kill         # Mata processo na porta 8000
```


## ğŸ“ Boas PrÃ¡ticas

### DAGs
- âœ… Todas as DAGs devem ter `tags` definidas
- âœ… `retries` deve ser >= 2
- âœ… Use `catchup=False` para evitar backfills indesejados
- âœ… Defina `depends_on_past` apropriadamente

### CÃ³digo
- âœ… Siga PEP 8 (use `black` e `isort`)
- âœ… Escreva testes para novas DAGs
- âœ… Documente funÃ§Ãµes e classes complexas
- âœ… Use type hints

## ğŸ” SeguranÃ§a

âš ï¸ **IMPORTANTE**: 
- **Nunca commite credenciais no cÃ³digo** - Passwords, tokens e API keys devem estar no `.env`
- **Use Airflow Connections e Variables** - Dados sensÃ­veis gerenciados pelo Airflow
- **Utilize Azure Key Vault** - Para secrets em produÃ§Ã£o
- **Mantenha o arquivo `.env` no `.gitignore`** - JÃ¡ configurado
- **Use placeholders genÃ©ricos** - Em documentaÃ§Ã£o e templates (ex: `XXXX-XXXXXX`, `your.email@example.com`)
- **NÃ£o exponha IDs reais** - Cluster IDs, Job IDs, emails pessoais devem ser secrets

### ğŸ”’ Boas PrÃ¡ticas de Secrets

âœ… **FaÃ§a:**
```bash
# Use variÃ¡veis de ambiente
DATABRICKS_TOKEN=${DATABRICKS_TOKEN}
DATABRICKS_CLUSTER_ID=${DATABRICKS_CLUSTER_ID}

# Use Airflow Variables
cluster_id = Variable.get("databricks_cluster_id")
```

âŒ **NÃ£o FaÃ§a:**
```python
# NUNCA hardcode valores reais
token = "dapi123456789..."  # âŒ
cluster_id = "0626-205409-935ntddc"  # âŒ
email = "meu.email@real.com"  # âŒ
```

### ğŸ­ Placeholders Recomendados

Use estes formatos em documentaÃ§Ã£o e exemplos:

| Tipo | Placeholder | Exemplo |
|------|-------------|---------|
| **Databricks Cluster** | `XXXX-XXXXXX-XXXXXXXX` | `1234-567890-abcd1234` |
| **Job ID** | `XXXXXXXXXXXXX` | `1234567890123` |
| **Token** | `dapi********************************` | `dapi1234...` |
| **Email** | `your.email@example.com` | `user@example.com` |
| **GUID/UUID** | `xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx` | `12345678-...` |
| **Password** | `YOUR_PASSWORD_HERE` | - |

## ğŸ“ˆ Monitoramento

- **Airflow UI**: Monitore execuÃ§Ãµes, logs e mÃ©tricas
- **Azure Monitor**: Acompanhe recursos Azure
- **Databricks Jobs**: Verifique execuÃ§Ã£o de notebooks

## ğŸ¤ Contribuindo

1. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
2. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`)
3. Push para a branch (`git push origin feature/nova-feature`)
4. Abra um Pull Request

## ğŸ“š Recursos Adicionais

### DocumentaÃ§Ã£o Externa
- [Apache Airflow Documentation](https://airflow.apache.org/docs/)
- [Astronomer Documentation](https://docs.astronomer.io/)
- [Azure Data Factory](https://docs.microsoft.com/azure/data-factory/)
- [Databricks Documentation](https://docs.databricks.com/)
- [Azure Key Vault Best Practices](https://docs.microsoft.com/azure/key-vault/general/best-practices)

## ğŸ› Troubleshooting

### ğŸ” DiagnÃ³stico Geral

```bash
# Verifique logs do Airflow
astro dev logs

# Verifique logs de um serviÃ§o especÃ­fico
astro dev logs --scheduler
astro dev logs --webserver

# Liste DAGs e erros de import
astro dev run dags list-import-errors
```

### âŒ DAG nÃ£o aparece no Airflow

**Sintomas:** DAG nÃ£o aparece na interface web

**SoluÃ§Ãµes:**
```bash
# 1. Verifique erros de sintaxe Python
python3 dags/seu_dag.py

# 2. Verifique erros de import no Airflow
astro dev run dags list-import-errors

# 3. Force refresh do scheduler
astro dev restart
```

### ğŸ”Œ Problemas de ConexÃ£o Azure SQL

**Sintomas:** `Error connecting to database`, `ODBC Driver not found`

**SoluÃ§Ãµes:**
```bash
# 1. Verifique se o ODBC Driver estÃ¡ instalado
astro dev bash
odbcinst -q -d

# 2. Teste a conexÃ£o
astro dev run connections test azure_sql_default

# 3. Verifique variÃ¡veis de ambiente
astro dev run variables list

# 4. Rebuild com cache limpo
astro dev stop
astro dev kill
astro dev start --build
```

**Erro comum:**
```
pyodbc.Error: ('01000', "[01000] [unixODBC][Driver Manager]Can't open lib 'ODBC Driver 18 for SQL Server'")
```
**SoluÃ§Ã£o:** O Dockerfile nÃ£o foi buildado corretamente. Execute `astro dev kill` e `astro dev start`.

### ğŸ”‘ Problemas com VariÃ¡veis de Ambiente

**Sintomas:** `KeyError`, variables vazias, connections nÃ£o funcionam

**SoluÃ§Ãµes:**
```bash
# 1. Verifique se o .env existe
ls -la .env

# 2. Verifique o conteÃºdo (sem expor secrets)
cat .env | grep -v "PASSWORD\|TOKEN\|SECRET"

# 3. Verifique se as variÃ¡veis estÃ£o sendo lidas
astro dev run variables list

# 4. Restart para recarregar .env
astro dev restart
```

### ğŸ³ Container nÃ£o inicia

**Sintomas:** Container fica em loop de restart ou falha ao iniciar

**SoluÃ§Ãµes:**
```bash
# 1. Limpe tudo e reconstrua
astro dev stop
astro dev kill
docker system prune -a --volumes  # âš ï¸ Remove TODOS os containers/volumes
astro dev start

# 2. Verifique portas em uso
lsof -i :8080
lsof -i :5432

# 3. Verifique espaÃ§o em disco
df -h

# 4. Verifique memÃ³ria disponÃ­vel
docker stats
```

### ğŸ“Š DAG travada ou nÃ£o executa

**Sintomas:** DAG mostra "running" mas nÃ£o progride

**SoluÃ§Ãµes:**
```bash
# 1. Verifique tasks em execuÃ§Ã£o
astro dev run tasks list

# 2. Clear task especÃ­fica
astro dev run tasks clear <dag_id> -t <task_id>

# 3. Verifique pools disponÃ­veis
astro dev run pools list

# 4. Aumente slots do pool se necessÃ¡rio
astro dev run pools set <pool_name> 10
```

### ğŸ” Erro de AutenticaÃ§Ã£o (Azure/Databricks)

**Sintomas:** `Authentication failed`, `Invalid token`, `403 Forbidden`

**Checklist:**
- [ ] VariÃ¡veis de ambiente estÃ£o corretas no `.env`
- [ ] Tokens nÃ£o expiraram
- [ ] Service Principal tem permissÃµes corretas
- [ ] Firewall/Network estÃ¡ permitindo conexÃ£o
- [ ] Connections no Airflow estÃ£o apontando para as variÃ¡veis certas

```bash
# Teste manualmente a autenticaÃ§Ã£o
astro dev bash
python3 -c "import os; print(os.getenv('DATABRICKS_TOKEN'))"
```

### ğŸ“ Logs Ãšteis

```bash
# Logs do scheduler (processamento de DAGs)
astro dev logs --scheduler --follow

# Logs do webserver (interface web)
astro dev logs --webserver --follow

# Logs de uma task especÃ­fica
astro dev run tasks logs <dag_id> <task_id> <execution_date>

# Entre no container para debug
astro dev bash
```

---

## ğŸš€ CI/CD Pipeline

O projeto possui um **pipeline completo de CI/CD** configurado com **GitHub Actions**, garantindo qualidade, seguranÃ§a e automaÃ§Ã£o em todo o ciclo de desenvolvimento.

### ğŸ“‹ Workflows DisponÃ­veis

#### 1. **CI - Continuous Integration** (`ci.yml`)

Executa em **push** e **pull requests** para branches `main` e `develop`.

**Jobs:**
- ğŸ¨ **Lint & Format Check** - Black, isort
- ğŸ§ª **Unit Tests** - pytest com coverage (>60%)
- ğŸ”’ **Security Checks** - Bandit, TruffleHog
- âœˆï¸ **DAG Validation** - Valida sintaxe de todas as DAGs
- ğŸ³ **Docker Build Test** - Build da imagem Docker
- ğŸ“š **Documentation Build** - Build do MkDocs

**DuraÃ§Ã£o:** ~5-8 minutos

---

#### 2. **CD - Continuous Deployment** (`cd.yml`)

Executa em **push para main** ou **tags vX.X.X**.

**Jobs:**
- ğŸ“¦ **Create Release** - Cria release no GitHub (apenas para tags)
- ğŸ“š **Deploy Documentation** - Publica docs no GitHub Pages
- ğŸ³ **Docker Push** - Envia imagem para GHCR
- ğŸš€ **Deploy to Astronomer** (opcional, desabilitado por padrÃ£o)

**DuraÃ§Ã£o:** ~3-5 minutos

---

#### 3. **Security Scanning** (`security.yml`)

Executa em **push, PRs** e **semanalmente** (segunda-feira 9h).

**Scans:**
- ğŸ” **Secret Scanning** - TruffleHog
- ğŸ”’ **Dependency Audit** - Safety
- ğŸ›¡ï¸ **SAST** - Bandit
- ğŸ”¬ **CodeQL Analysis** - GitHub Advanced Security
- ğŸ³ **Docker Security** - Trivy
- âš–ï¸ **License Compliance** - pip-licenses

**DuraÃ§Ã£o:** ~10-12 minutos

---

#### 4. **PR Checks** (`pr-checks.yml`)

Executa em **pull requests** para adicionar automaÃ§Ã£o.

**Features:**
- ğŸ“ **PR Title Check** - Valida Conventional Commits
- ğŸ“ **PR Size Check** - Calcula tamanho do PR
- âœ… **PR Checklist** - Posta checklist automÃ¡tico
- ğŸ·ï¸ **Auto Labeler** - Adiciona labels baseado em arquivos alterados

---

### ğŸ”§ ConfiguraÃ§Ãµes Adicionais

#### **Dependabot** (`dependabot.yml`)
- ğŸ“¦ Atualiza dependÃªncias Python semanalmente
- ğŸ”„ Atualiza GitHub Actions mensalmente
- ğŸ³ Atualiza Dockerfile mensalmente

#### **Code Owners** (`CODEOWNERS`)
- ğŸ‘¤ Define revisores automÃ¡ticos por arquivo/diretÃ³rio
- âœ… Garante revisÃ£o de mudanÃ§as crÃ­ticas

#### **Issue Templates**
- ğŸ› Bug Report
- âœ¨ Feature Request

#### **PR Template**
- ğŸ“‹ Checklist completo
- ğŸ·ï¸ Labels automÃ¡ticas
- âœ… Status de CI

---

### ğŸ¯ Como Usar o CI/CD

#### **Desenvolvimento Normal**

```bash
# 1. Crie uma branch
git checkout -b feat/nova-dag

# 2. FaÃ§a suas mudanÃ§as
# ... edite cÃ³digo ...

# 3. Rode testes localmente (opcional, mas recomendado)
poetry run task test
poetry run task lint

# 4. Commit seguindo Conventional Commits
git commit -m "feat: add new data quality DAG"

# 5. Push para o GitHub
git push origin feat/nova-dag
```

**O CI vai automaticamente:**
- âœ… Rodar lint
- âœ… Executar testes
- âœ… Fazer security scan
- âœ… Validar DAGs
- âœ… Build Docker

---

#### **Criando uma Release**

```bash
# 1. Crie uma tag com semantic versioning
git tag -a v1.0.0 -m "Release version 1.0.0"

# 2. Push da tag
git push origin v1.0.0
```

**O CD vai automaticamente:**
- ğŸ“¦ Criar release no GitHub
- ğŸ“š Publicar documentaÃ§Ã£o
- ğŸ³ Enviar imagem Docker

---

### ğŸ“Š Monitorando CI/CD

- **Status:** Veja badges no topo do README
- **Detalhes:** Acesse a aba **Actions** no GitHub
- **Security:** Acesse a aba **Security** no GitHub
- **Coverage:** Download artifacts do workflow CI

---

### ğŸ›¡ï¸ Security Scanning Schedule

| Scan | FrequÃªncia | Job |
|------|------------|-----|
| Secret Scanning | Push/PR + Semanal | TruffleHog |
| Dependency Audit | Push/PR + Semanal | Safety |
| SAST | Push/PR + Semanal | Bandit |
| CodeQL | Push/PR + Semanal | GitHub |
| Docker Security | Push/PR + Semanal | Trivy |

---

### ğŸ”— Links Ãšteis

- [GitHub Actions Docs](https://docs.github.com/en/actions)
- [Astronomer Deploy Guide](https://docs.astronomer.io/astro/deploy-code)
- [Conventional Commits](https://www.conventionalcommits.org/)

---

## ğŸ“„ LicenÃ§a

Este projeto foi desenvolvido como parte de um desafio tÃ©cnico.

## âœï¸ Autor

**Victor Castro**
- Email: victorcappelletto@gmail.com

---

â­ Se este projeto foi Ãºtil, considere dar uma estrela!
