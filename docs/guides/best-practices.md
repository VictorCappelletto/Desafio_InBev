# Boas PrÃ¡ticas

## ğŸ¯ PrincÃ­pios Gerais

### 1. SeguranÃ§a em Primeiro Lugar

!!! danger "NUNCA faÃ§a isso"
    ```python
    # âŒ Senha hardcoded
    password = "minha_senha_123"
    
    # âŒ Token no cÃ³digo
    databricks_token = "dapi1234567890"
    
    # âŒ IDs reais em documentaÃ§Ã£o
    cluster_id = "0626-205409-935ntddc"
    ```

!!! success "SEMPRE faÃ§a isso"
    ```python
    # âœ… Usar configuraÃ§Ãµes
    from config import AzureSQLConfig
    config = AzureSQLConfig()  # LÃª de environment
    
    # âœ… Usar Airflow Variables
    cluster_id = Variable.get("databricks_cluster_id")
    
    # âœ… Placeholders em docs
    cluster_id = "XXXX-XXXXXX-XXXXXXXX"
    ```

### 2. Sempre Use Dependency Injection

!!! example "Dependency Injection"
    ```python
    # âœ… BOM - Injetar dependÃªncias
    class BreweryAPIExtractor:
        def __init__(self, config: APIConfig):
            self.config = config
    
    # FÃ¡cil de testar
    mock_config = APIConfig(brewery_api_url="http://test")
    extractor = BreweryAPIExtractor(mock_config)
    ```

### 3. Single Responsibility

!!! tip "Uma classe, uma responsabilidade"
    ```python
    # âœ… BOM - Classes focadas
    class BreweryAPIExtractor:
        """Apenas extrai dados"""
        def extract(self): ...
    
    class BreweryTransformer:
        """Apenas transforma dados"""
        def transform(self, data): ...
    
    class AzureSQLLoader:
        """Apenas carrega dados"""
        def load(self, data): ...
    
    # âŒ RUIM - Classe faz tudo
    class BreweryProcessor:
        def process(self):
            # Extrai, transforma e carrega tudo aqui
            ...
    ```

## ğŸ“ DAGs

### Estrutura PadrÃ£o

```python
"""
DAG Description

Detailed explanation of what this DAG does.
"""

# 1. Imports organizados
from datetime import datetime, timedelta
from airflow import DAG
from airflow.operators.python import PythonOperator

# ConfiguraÃ§Ãµes
from config import AirflowConfig, APIConfig
from factories import ETLFactory
from utils.logger import get_logger

# 2. ConfiguraÃ§Ã£o global
config = AirflowConfig()
logger = get_logger(__name__)

# 3. FunÃ§Ãµes de task
def my_task(**context):
    """Task docstring."""
    log_task_start(logger, "my_task")
    try:
        # LÃ³gica
        result = do_something()
        log_task_success(logger, "my_task", records=result)
    except Exception as e:
        log_task_error(logger, "my_task", e)
        raise

# 4. Default args
default_args = {
    'owner': 'airflow',
    'depends_on_past': False,
    'start_date': datetime(2024, 10, 1),
    'retries': config.default_retries,
    'retry_delay': timedelta(seconds=config.retry_delay_seconds),
}

# 5. DAG definition
with DAG(
    'my_dag_name',
    default_args=default_args,
    description='Clear description',
    schedule_interval='@daily',
    catchup=False,
    tags=['category', 'solid', 'production'],
) as dag:
    
    task1 = PythonOperator(
        task_id='task1',
        python_callable=my_task,
        doc_md="""
        ### Task Documentation
        
        What this task does.
        """,
    )
```

### Naming Conventions

| Tipo | ConvenÃ§Ã£o | Exemplo |
|------|-----------|---------|
| **DAG** | `{domain}_{action}_{tech}` | `brewery_etl_solid` |
| **Task** | `{verb}_{noun}_task` | `extract_data_task` |
| **Variable** | `snake_case` | `databricks_cluster_id` |
| **Class** | `PascalCase` | `BreweryAPIExtractor` |
| **Function** | `snake_case` | `extract_brewery_data` |

### Tags

Use tags para organizar DAGs:

```python
tags = [
    'etl',           # Tipo de processo
    'brewery',       # DomÃ­nio
    'azure-sql',     # Tecnologia
    'solid',         # Arquitetura
    'production',    # Ambiente
]
```

## ğŸ”§ CÃ³digo Python

### Type Hints

!!! success "SEMPRE use type hints"
    ```python
    def extract_data(config: APIConfig) -> List[Dict[str, Any]]:
        """Extract data from API."""
        ...
    
    class BreweryExtractor:
        def __init__(self, config: APIConfig) -> None:
            self.config: APIConfig = config
    ```

### Docstrings

Use Google Style:

```python
def load_data(data: List[Dict], config: AzureSQLConfig) -> int:
    """
    Load brewery data to Azure SQL.
    
    Args:
        data: List of brewery dictionaries
        config: Azure SQL configuration
        
    Returns:
        Number of records loaded
        
    Raises:
        LoadError: If loading fails
        
    Example:
        >>> loader = AzureSQLLoader(config)
        >>> count = loader.load(data)
        >>> print(f"Loaded {count} records")
    """
    ...
```

### Error Handling

```python
# âœ… BOM - ExceÃ§Ãµes especÃ­ficas
try:
    data = extractor.extract()
except ExtractionError as e:
    logger.error(f"Failed to extract: {e}")
    raise
except ValidationError as e:
    logger.error(f"Validation failed: {e}")
    raise
finally:
    cleanup_resources()

# âŒ RUIM - Catch genÃ©rico
try:
    data = extractor.extract()
except Exception as e:  # Muito genÃ©rico!
    print("Error!")  # NÃ£o use print!
```

### Logging

!!! tip "Use o sistema de logging"
    ```python
    from utils.logger import get_logger, log_task_start
    
    logger = get_logger(__name__)
    
    # InÃ­cio da task
    log_task_start(logger, "extract", source="API")
    
    # Sucesso com mÃ©tricas
    log_task_success(
        logger,
        "extract",
        records=100,
        duration="2.3s"
    )
    
    # Erro com contexto
    log_task_error(
        logger,
        "extract",
        error,
        retry_count=1
    )
    ```

## ğŸ§ª Testes

### Estrutura de Testes

```
tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ test_extractors.py
â”‚   â”œâ”€â”€ test_loaders.py
â”‚   â””â”€â”€ test_transformers.py
â”œâ”€â”€ integration/
â”‚   â””â”€â”€ test_etl_pipeline.py
â””â”€â”€ conftest.py
```

### Unit Tests

```python
import pytest
from config import APIConfig
from services import BreweryAPIExtractor

def test_brewery_extractor():
    # Arrange
    config = APIConfig(brewery_api_url="http://test")
    extractor = BreweryAPIExtractor(config)
    
    # Act
    data = extractor.extract()
    
    # Assert
    assert len(data) > 0
    assert extractor.validate_data(data)
```

### Mock Configs

```python
from unittest.mock import Mock

def test_with_mock():
    # Mock extractor
    mock_extractor = Mock(spec=IDataExtractor)
    mock_extractor.extract.return_value = [
        {'id': '1', 'name': 'Test'}
    ]
    
    # Test
    pipeline = ETLPipeline(extractor=mock_extractor)
    result = pipeline.run()
    
    # Assert
    mock_extractor.extract.assert_called_once()
```

## ğŸ“Š Monitoramento

### MÃ©tricas Importantes

```python
# Registre sempre
log_task_success(
    logger,
    "extract",
    records=len(data),        # Quantidade
    duration="2.3s",          # Tempo
    api_status=200,           # Status
    source="brewery_api"      # Origem
)
```

### Alertas

Configure alertas para:
- âŒ DAG failures
- â±ï¸ Tasks lentas (>threshold)
- ğŸ“‰ Queda na quantidade de dados
- ğŸ”„ Muitos retries

### SLAs

```python
with DAG(
    'critical_dag',
    sla_miss_callback=notify_team,
    default_args={
        'sla': timedelta(hours=2),  # SLA de 2 horas
    }
) as dag:
    ...
```

## ğŸ” SeguranÃ§a

### Checklist de SeguranÃ§a

- [ ] Nenhuma senha no cÃ³digo
- [ ] `.env` no `.gitignore`
- [ ] Connections via Airflow
- [ ] Variables para configs sensÃ­veis
- [ ] Placeholders em docs
- [ ] Logs nÃ£o expÃµem secrets
- [ ] Service Principals (nÃ£o users)

### Azure Key Vault (ProduÃ§Ã£o)

```python
from azure.keyvault.secrets import SecretClient
from azure.identity import DefaultAzureCredential

credential = DefaultAzureCredential()
client = SecretClient(
    vault_url="https://my-vault.vault.azure.net",
    credential=credential
)

secret = client.get_secret("databricks-token")
token = secret.value
```

## ğŸ“š DocumentaÃ§Ã£o

### README de DAG

Cada DAG deve ter:
- DescriÃ§Ã£o clara
- DependÃªncias
- ConfiguraÃ§Ãµes necessÃ¡rias
- Exemplo de execuÃ§Ã£o
- Troubleshooting comum

### ComentÃ¡rios

```python
# âœ… BOM - Explica o "porquÃª"
# MERGE instead of INSERT to handle duplicates
cursor.execute(merge_sql, ...)

# âŒ RUIM - Explica o "o quÃª" (Ã³bvio)
# Execute SQL
cursor.execute(sql)
```

## ğŸš€ Performance

### OtimizaÃ§Ãµes

```python
# âœ… BOM - Batch loading
def load_batch(data: List[Dict]):
    with connection() as conn:
        cursor.executemany(sql, data)  # Batch!

# âŒ RUIM - Loading individual
for record in data:
    cursor.execute(sql, record)  # Lento!
```

### Connection Pooling

```python
# âœ… BOM - Context manager
def get_data():
    with get_connection() as conn:
        cursor = conn.cursor()
        return cursor.fetchall()
    # Connection fechada automaticamente

# âŒ RUIM - Connections abertas
conn = get_connection()
cursor = conn.cursor()
# Nunca fecha!
```

## ğŸ“– Saiba Mais

- [Arquitetura SOLID â†’](../architecture/overview.md)
- [Troubleshooting â†’](troubleshooting.md)
- [Deployment â†’](deployment.md)

