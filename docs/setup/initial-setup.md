# Setup Inicial

## üéØ Pr√©-requisitos

Antes de come√ßar, certifique-se de ter:

- ‚úÖ **Python 3.11+**
- ‚úÖ **Docker & Docker Compose**
- ‚úÖ **Astronomer CLI** (opcional, mas recomendado)
- ‚úÖ **Poetry** (gerenciador de depend√™ncias Python)
- ‚úÖ **Git**

## üì• Instala√ß√£o

### 1. Clone o Reposit√≥rio

```bash
git clone https://github.com/victorcappelleto/Desafio_InBev.git
cd Desafio_InBev
```

### 2. Instale Astronomer CLI

=== "macOS"

    ```bash
    brew install astro
    ```

=== "Linux"

    ```bash
    curl -sSL install.astronomer.io | sudo bash -s
    ```

=== "Windows"

    ```powershell
    winget install -e --id Astronomer.Astro
    ```

### 3. Configure Vari√°veis de Ambiente

```bash
# Copie o template
cp env.template .env

# Edite com suas credenciais
nano .env  # ou vim, code, etc
```

**Exemplo de `.env`:**
```bash
# Azure SQL
AZURE_SQL_PASSWORD=SuaSenhaSegura

# Databricks
DATABRICKS_HOST=https://adb-12345.azuredatabricks.net
DATABRICKS_TOKEN=dapi1234567890abcdef
DATABRICKS_CLUSTER_ID=1234-567890-abcd1234
DATABRICKS_JOB_ID=1234567890123
DATABRICKS_NOTEBOOK_PATH=/Workspace/Users/seu.email@empresa.com/notebook

# Azure Data Factory
ADF_TENANT_ID=12345678-1234-1234-1234-123456789012
ADF_SUBSCRIPTION_ID=12345678-1234-1234-1234-123456789012
ADF_CLIENT_ID=12345678-1234-1234-1234-123456789012
ADF_CLIENT_SECRET=SeuClientSecret
```

!!! warning "Seguran√ßa"
    **NUNCA** commite o arquivo `.env`! Ele j√° est√° no `.gitignore`.

### 4. Inicie o Ambiente Airflow

```bash
# Com Astronomer CLI (recomendado)
astro dev start

# Ou com Docker Compose puro
docker-compose up -d
```

### 5. Acesse a Interface Web

```bash
# Abra no navegador
open http://localhost:8080

# Ou
# http://localhost:8080
```

**Credenciais padr√£o:**
- **Username:** `admin`
- **Password:** `admin`

## ‚úÖ Verifica√ß√£o

### 1. Verifique os Containers

```bash
astro dev ps

# Deve mostrar:
# - webserver (porta 8080)
# - scheduler
# - postgres
# - triggerer
```

### 2. Verifique as DAGs

```bash
# Liste as DAGs
astro dev run dags list

# Deve mostrar:
# - brewery_etl_solid
# - databricks_processing_solid
# - azure_data_factory_solid
```

### 3. Teste uma Conex√£o

```bash
# Teste a conex√£o Azure SQL
astro dev run connections test azure_sql_default

# Deve retornar: Connection successfully tested
```

### 4. Verifique ODBC Driver

```bash
# Entre no container
astro dev bash

# Verifique drivers instalados
odbcinst -q -d

# Deve mostrar: [ODBC Driver 18 for SQL Server]
```

## üîß Configura√ß√£o Adicional

### Pools

Os pools j√° est√£o pr√©-configurados em `airflow_settings.yaml`:

```yaml
pools:
  - pool_name: azure_pool
    pool_slot: 5
  - pool_name: databricks_pool
    pool_slot: 3
```

**Verificar pools:**
```bash
astro dev run pools list
```

### Variables

As variables tamb√©m est√£o pr√©-configuradas:

```bash
# Listar variables
astro dev run variables list

# Deve mostrar:
# - databricks_cluster_id
# - databricks_job_id
# - databricks_notebook_path
# - adf_resource_group
# ...
```

### Connections

Conex√µes pr√©-configuradas:
- `azure_sql_default` - Azure SQL Database
- `databricks_default` - Databricks
- `azure_data_factory_default` - Azure Data Factory

**Verificar connections:**
```bash
astro dev run connections list
```

## üöÄ Primeira Execu√ß√£o

### 1. Ative uma DAG

Na interface web:
1. Navegue para http://localhost:8080
2. Encontre `brewery_etl_solid`
3. Toggle o switch para **ON**
4. Clique em "Trigger DAG" (√≠cone play)

### 2. Monitore a Execu√ß√£o

```bash
# Logs em tempo real
astro dev logs --follow

# Logs de uma DAG espec√≠fica
astro dev logs --scheduler --follow
```

### 3. Verifique os Resultados

1. Acesse "DAGs" na interface
2. Clique em `brewery_etl_solid`
3. Visualize o "Graph View"
4. Clique em cada task para ver logs

## üêõ Troubleshooting

### Container n√£o inicia

```bash
# Pare tudo
astro dev stop

# Limpe volumes
astro dev kill

# Reinicie
astro dev start
```

### ODBC Driver n√£o encontrado

```bash
# Rebuild com cache limpo
astro dev stop
astro dev start --build
```

### Conex√£o Azure SQL falha

1. Verifique `.env` - senha correta?
2. Verifique firewall Azure - IP permitido?
3. Teste manualmente:
   ```bash
   astro dev bash
   python -c "import pyodbc; print(pyodbc.drivers())"
   ```

### DAG n√£o aparece

```bash
# Verifique erros de sintaxe
python dags/brewery_etl_dag.py

# Verifique erros de import
astro dev run dags list-import-errors
```

## üìö Pr√≥ximos Passos

- [Configurar Connections ‚Üí](connections.md)
- [Entender as DAGs ‚Üí](../dags/introduction.md)
- [Boas Pr√°ticas ‚Üí](../guides/best-practices.md)
- [Troubleshooting Completo ‚Üí](../guides/troubleshooting.md)

